{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zusammenfügen von Datensätzen in `pandas`\n",
    "\n",
    "Wir kennen in Pandas nun schon `pd.concat`. Diese Funktion dient zum \n",
    "*einfachen* Aneinanderfügen von Tabellen, ohne Berücksichtigung von Spalten,\n",
    " die diese gemeinsam haben.\n",
    "\n",
    "Heute lernen wir, wie wir Tabellen basierend auf übereinstimmenden Spalten \n",
    "(z.B. Bestell-ID; Modellnummer; ...) zusammenfügen. Dabei werden anhand der\n",
    " Indizes oder anhand einer gemeinsamen Spalte Einträge verbunden, die in \n",
    " beiden Tabellen übereinstimmen. Wir kennen diese \"Joins\" noch aus Excel \n",
    " mit den Funktionen `SVERWEIS()` und `INDEX(VERGLEICH())` und aus Power \n",
    " Query. In Pandas benutzt man mit die DataFrame-Methoden `join()` und `merge()`.\n",
    "\n",
    "Hierfür ist es nützlich, sich noch einmal die verschiedenen Arten anzuschauen, auf\n",
    "  die man Tabellen zusammenfügen kann – die sogenannten Joins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T16:59:46.353283700Z",
     "start_time": "2024-01-27T16:59:45.873485300Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Anfügen von Daten: pd.concat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T17:00:40.617963800Z",
     "start_time": "2024-01-27T17:00:40.598506600Z"
    }
   },
   "outputs": [],
   "source": [
    "# Series mit Temperatur-Messwerten:\n",
    "data = [4.5, 6.3, 3.8, 5.1, 4.9, 5.7, 4.2, 6.0]\n",
    "temp_series = pd.Series(data, name=\"Temperatur\")\n",
    "temp_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T17:00:42.070886900Z",
     "start_time": "2024-01-27T17:00:42.063039200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Series mit Zeitstempeln für Messzeitpunkt:\n",
    "uhrzeiten = ['2023-01-02 19:08',\n",
    "             '2023-01-04 18:17',\n",
    "             '2023-01-06 06:03',\n",
    "             '2023-01-09 02:17',\n",
    "             '2023-01-12 22:02',\n",
    "             '2023-01-17 16:00',\n",
    "             '2023-01-22 21:04',\n",
    "             '2023-01-24 11:16']\n",
    "\n",
    "# Eigentlich besser, man macht datetime-Objekte daraus, aber das Thema kommt erst später dran,\n",
    "# bitte also Geduld ;)\n",
    "\n",
    "# So könnte man das tun: pd.Series(pd.to_datetime(uhrzeiten))\n",
    "\n",
    "time_series = pd.Series(uhrzeiten, name=\"Zeitstempel\")\n",
    "time_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Beide Serien zu einem DataFrame verbinden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T17:00:49.907403900Z",
     "start_time": "2024-01-27T17:00:49.896070500Z"
    }
   },
   "outputs": [],
   "source": [
    "# temp_series und time_series verbinden\n",
    "temps_df = pd.concat([time_series, temp_series], axis=1)\n",
    "temps_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Was, wenn die Indices nicht so gut zusammenspielen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T17:01:21.676798900Z",
     "start_time": "2024-01-27T17:01:21.666452300Z"
    }
   },
   "outputs": [],
   "source": [
    "# Eigene Indizes vergeben:\n",
    "\n",
    "time_series_2 = time_series.copy()\n",
    "# Lücken: 0, 1, 4, 10\n",
    "time_series_2.index = [2, 3, 5, 6, 7, 8, 9, 11]\n",
    "\n",
    "temp_series_2 = temp_series.copy()\n",
    "# Lücken: 1, 3, 9, 11\n",
    "temp_series_2.index = [0, 2, 4, 5, 6, 7, 8, 10]\n",
    "\n",
    "print(time_series_2)\n",
    "print(temp_series_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T17:02:06.212162Z",
     "start_time": "2024-01-27T17:02:06.197642700Z"
    }
   },
   "outputs": [],
   "source": [
    "# Serien mit benannten indizes verbinden\n",
    "# Erzeugt NaN, wenn Indices nicht in beiden Serien vorkommen\n",
    "temps_df2 = pd.concat([time_series_2, temp_series_2],\n",
    "                 axis=1)\n",
    "\n",
    "temps_df2.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index muss in beiden Serien einzigartig sein (Keine Duplikate)!\n",
    "# Sonst funktioniert concat nicht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "temp_series_3 = temp_series.copy()\n",
    "temp_series_3.index = [2, 3, 5, 6, 7, 7, 9, 11]\n",
    "\n",
    "time_series_3 = time_series.copy()\n",
    "time_series_3.index = [0, 2, 2, 5, 6, 7, 8, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temps_df3 = pd.concat([time_series_3, temp_series_3],\n",
    "                       axis=1)\n",
    "\n",
    "temps_df3.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verbinden über Index-Vergleich\n",
    "\n",
    "\n",
    "### `DataFrame.join`\n",
    "\n",
    "Verwendet den Index oder eine bestimmte Spalte des DataFrames, der die Methode aufruft und fügt die Daten übereinstimmender Indizes des anderen DataFrames seitlich an. \n",
    "\n",
    "Für weitere Infos: [Link](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.join.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T17:10:10.137826800Z",
     "start_time": "2024-01-27T17:10:10.127433100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Erstellen zweier DataFrames mit\n",
    "# unterschiedlichen Indices\n",
    "contacts1 = pd.DataFrame({\"Name\": [\"Franz\", \"Lena\", \"Chloé\"],\n",
    "                    \"Alter\": [\"67\", \"31\", \"41\"]},\n",
    "                   index=[\"K0\", \"K1\", \"K2\"])\n",
    "\n",
    "contacts2 = pd.DataFrame({\"Wohnort\": [\"Rostock\", \"Nürnberg\", \"Berlin\"],\n",
    "                    \"Telefonnummer\": [\"030 215783\", \"030 847735\", \"030 781404\"]},\n",
    "                   index=[\"K0\", \"K2\", \"K3\"])\n",
    "\n",
    "print(contacts1)\n",
    "print()\n",
    "print(contacts2)\n",
    "# Was stellen wir an den DataFrames fest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T17:10:32.858626900Z",
     "start_time": "2024-01-27T17:10:32.845818500Z"
    }
   },
   "outputs": [],
   "source": [
    "# pd.concat kann zwar auch joins, aber nur inner \n",
    "# oder outer join (kein left oder right join)\n",
    "# Standardverhalten ist übrigens: outer und erzeugt potentiell NaNs:\n",
    "pd.concat([contacts1, contacts2], axis=1, join=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T17:10:48.083384900Z",
     "start_time": "2024-01-27T17:10:48.073450100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.concat([contacts1, contacts2], axis=1, join=\"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataFrame.join() ermöglicht weitere Joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T17:12:01.183510100Z",
     "start_time": "2024-01-27T17:12:01.179182700Z"
    }
   },
   "outputs": [],
   "source": [
    "# Left Join (Standardverhalten von join!)\n",
    "# Alle Keys aus dem ERSTEN (linken) Datensatz werden genutzt\n",
    "# und um Daten aus dem andern (rechten) Datensatz ergänzt.\n",
    "# An Indexpositionen, über die der rechte Datensatz nicht verfügt, entstehen NaNs:\n",
    "contacts1.join(contacts2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T17:12:02.957723800Z",
     "start_time": "2024-01-27T17:12:02.947236400Z"
    }
   },
   "outputs": [],
   "source": [
    "# Von contacts2 kommend entstehen die Lücken an anderen Stellen, wo eben contacts1 keine Indices hat:\n",
    "contacts2.join(contacts1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T17:12:39.422407200Z",
     "start_time": "2024-01-27T17:12:39.410355900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Right join\n",
    "# Keys der rechten (zweiten) Datensatzes werden genutzt,\n",
    "# und um entsprechende Daten aus dem linken (ersten) ergänzt.\n",
    "# Wo der erste keine Indices hat, entstehen NaNs \n",
    "contacts1.join(contacts2, how=\"right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T17:13:50.162347600Z",
     "start_time": "2024-01-27T17:13:50.146928400Z"
    }
   },
   "outputs": [],
   "source": [
    "# Outer join\n",
    "# Alle Keys aus BEIDEN Datensätzen werden genutzt\n",
    "# Maximale \"NaN-Dichte\" wird erreicht:\n",
    "contacts1.join(contacts2, how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T17:14:09.356921400Z",
     "start_time": "2024-01-27T17:14:09.341987600Z"
    }
   },
   "outputs": [],
   "source": [
    "# Inner join\n",
    "# Nur Keys, die in BEIDEN Datensätzen vorhanden sind\n",
    "# Es kommt zu keinen NaN-Werten (ist unmöglich!):\n",
    "contacts1.join(contacts2, how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T17:14:20.043389200Z",
     "start_time": "2024-01-27T17:14:20.030119200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Cross join\n",
    "# Erzeugt eine Kombination jeder Zeile des ersten Datensatzes\n",
    "# mit jeder Zeile des zweiten Datensatzes (hier nicht gerade sinnvoll)\n",
    "contacts1.join(contacts2, how=\"cross\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zusammenfügen mehrerer Datensätze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(contacts1)\n",
    "print()\n",
    "print(contacts2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T17:16:10.706847Z",
     "start_time": "2024-01-27T17:16:10.701285800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Mit zwei dfs kennen wir das Spiel schon:\n",
    "contacts1.join(contacts2, how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T17:19:54.358766900Z",
     "start_time": "2024-01-27T17:19:54.351367800Z"
    }
   },
   "outputs": [],
   "source": [
    "# Aber jetzt haben wir noch eine Nummer 3:\n",
    "contacts3 = pd.DataFrame({\"Position\": [\"Rentner\", \"Verkäuferin\", \"Data Engineer\"],\n",
    "                    \"Gehalt\": [\"1400\", \"3000\", \"3800\"]},\n",
    "                   index=[\"K1\", \"K3\", \"K4\"])\n",
    "\n",
    "contacts3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T17:19:55.276476300Z",
     "start_time": "2024-01-27T17:19:55.262688400Z"
    }
   },
   "outputs": [],
   "source": [
    "# joinen mehrerer dfs an contacts1 über Liste möglich:\n",
    "contacts1.join([contacts2, contacts3], how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bonusfrage: Was zum Teufel ist denn hier passiert?\n",
    "contacts1.join([contacts2, contacts3], how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bonus-Info!\n",
    "# join hat noch eine weitere Fähigkeit mit 'on'\n",
    "# Der join kann über eine wählbare Spalte aus dem linken DataFrame \n",
    "# mit dem Index des rechten DataFrames erfolgen.\n",
    "# Wir modifizieren contacts1, sodass dort die \"Indices\" in einer Spalte vorkommen!\n",
    "\n",
    "contacts1 = pd.DataFrame({\"Name\": [\"Franz\", \"Lena\", \"Chloé\"],\n",
    "                          \"Alter\": [\"67\", \"31\", \"41\"],\n",
    "                          \"Kontakt-ID\": [\"K0\", \"K1\", \"K2\"]})\n",
    "\n",
    "contacts2 = pd.DataFrame({\"Wohnort\": [\"Rostock\", \"Nürnberg\", \"Berlin\"],\n",
    "                          \"Telefonnummer\": [\"030 215783\", \"030 847735\", \"030 781404\"]}, \n",
    "                          index=[\"K0\", \"K2\", \"K3\"])\n",
    "\n",
    "print(contacts1)\n",
    "print()\n",
    "print(contacts2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contacts1.join(contacts2, on='Kontakt-ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aber man kann solche Dinge (und noch mehr) auch mit merge erreichen!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Beide Serien zu einem DataFrame verbinden\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Übungsaufgabe `concat` + `join`\n",
    "\n",
    "Zeit: 30 Minuten\n",
    "\n",
    "Gegeben sind Temperaturmessdaten (`temp`), Zeitstempel (`uhrzeiten`), \n",
    " Luftdruckdaten (`druck_dict`) und Geolokationsdaten (`geo_dict`).\n",
    "1. Wandel die Temperaturdaten und Zeitstempel in Series um und kombiniere \n",
    "sie anschließend zu einem DataFrame namens `temp_df`.\n",
    "2. Wandel die beiden Dictionaries jedes in jeweils einen DataFrame um (`druck_df`, `geo_df`).\n",
    "3. Füge die Druckdaten an den DataFrame aus 1. an und speichere den neuen \n",
    "DataFrame als `df_gesamt`.\n",
    "4. Kombiniere `df_gesamt` so mit dem Geolokalisation-DataFrame, dass du für \n",
    "jede in `df_gesamt` vorkommende Stadt die Breiten- und Längengrade im \n",
    "resultierenden DataFrame erhältst. (Tipp: Hierfür müssen die Indices \n",
    "verändert werden).\n",
    "\n",
    "    Output:\n",
    "    ```\n",
    "                        Zeitstempel  Temperatur  Luftdruck  Breitengrad  Laengengrad  \n",
    "    Location                                                              \n",
    "    Berlin         2023-01-01 19:08         4.5     1001.2        52.31        13.24\n",
    "    München        2023-01-01 18:17         6.3      997.8        48.80        11.34\n",
    "    Wilhelmshaven  2023-01-01 06:03         3.8     1002.5          NaN          NaN\n",
    "    Kassel         2023-01-01 02:17         5.1     1000.1        49.28      -123.13\n",
    "    Frankfurt      2023-01-01 22:02         4.9      998.9        47.61      -122.33\n",
    "    Duisburg       2023-01-01 16:00         5.7     1001.5        53.55      -113.49\n",
    "    Dresden        2023-01-01 21:04         4.2      999.2          NaN          NaN\n",
    "    Würzburg       2023-01-01 11:16         6.0     1002.8        51.05      -114.07\n",
    "    ```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T17:30:33.920543Z",
     "start_time": "2024-01-27T17:30:33.911559Z"
    }
   },
   "outputs": [],
   "source": [
    "# Temperatur-Messwerte\n",
    "temp = [4.5, 6.3, 3.8, 5.1, 4.9, 5.7, 4.2, 6.0]\n",
    "\n",
    "# Zeitstempel für Messzeitpunkt\n",
    "uhrzeiten = ['2023-01-01 19:08',\n",
    "             '2023-01-01 18:17',\n",
    "             '2023-01-01 06:03',\n",
    "             '2023-01-01 02:17',\n",
    "             '2023-01-01 22:02',\n",
    "             '2023-01-01 16:00',\n",
    "             '2023-01-01 21:04',\n",
    "             '2023-01-01 11:16']\n",
    "\n",
    "# Orte und Luftdruckmessung\n",
    "druck_dict = {'Location': ['Berlin', 'München', 'Wilhelmshaven',\n",
    "                           'Kassel', 'Frankfurt', 'Duisburg',\n",
    "                           'Dresden', 'Würzburg'],\n",
    "              'Luftdruck': [1001.2, 997.8, 1002.5, 1000.1, 998.9,\n",
    "                            1001.5, 999.2, 1002.8]}\n",
    "\n",
    "# Längen- und Breitengrade der Orte\n",
    "geo_dict = {'Location': ['Berlin', 'München', 'Hamburg', 'Köln',\n",
    "                         'Frankfurt', 'Duisburg', 'Kassel', 'Würzburg'],\n",
    "            'Breitengrad': [52.31, 48.8, 53.33, 45.75, 47.61,\n",
    "                            53.55, 49.28, 51.05],\n",
    "            'Laengengrad': [13.24, 11.34, 10.0, -122.43, -122.33,\n",
    "                            -113.49, -123.13, -114.07]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENDE ÜBUNG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `pandas.merge` (Datensätze zusammenfügen über Index oder / und Column)\n",
    "\n",
    "Bei `pd.merge` können wir ein `on=` Keyword angeben, wodurch wir Tabellen \n",
    "auch über normale Spalten statt über den Index zusammenführen können. Hier \n",
    "müssen nicht einmal die Spaltennamen zwingend übereinstimmen. Außerdem hat \n",
    "`merge` noch viele andere zusätzliche Optionen, die es bei `join` nicht \n",
    "gibt, zum Beispiel die Benutzung mehrerer Schlüsselspalten.\n",
    "\n",
    "Es gibt sogar eine `merge_asof` Funktion, welche auch ungenaue \n",
    "Übereinstimmungen erlaubt, ähnlich wie der optionale Parameter \n",
    "Bereich_Verweis in Excels SVERWEIS, wo eine ungenaue Übereinstimmung über \n",
    "\"WAHR\" festgelegt werden konnte.\n",
    "Jedoch gibt es auch hier in Pandas wieder viel mehr Einstellungsmöglichkeiten.\n",
    "\n",
    "Mehr Information: [Link](https://pandas.pydata.org/docs/reference/api/pandas.merge.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T17:30:41.332054100Z",
     "start_time": "2024-01-27T17:30:41.326868600Z"
    }
   },
   "outputs": [],
   "source": [
    "# DataFrame aus Übung erstellen vor dem Zusammenführen:\n",
    "df = pd.concat([time_series, temp_series, druck_df],\n",
    "               axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T17:36:03.739450500Z",
     "start_time": "2024-01-27T17:36:03.732444400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Geo-Dataframe soll gänzlich anderen Index haben.\n",
    "# Vorarbeit:\n",
    "geo_length = len(geo_dict['Location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T17:39:15.528308900Z",
     "start_time": "2024-01-27T17:39:15.506254600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "geo_df = pd.DataFrame(geo_dict, index=[f'Eintrag {i}' for i in range (geo_length)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T17:40:04.953342300Z",
     "start_time": "2024-01-27T17:40:04.938794300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "geo_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T17:39:17.789173900Z",
     "start_time": "2024-01-27T17:39:17.773968200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Zusammenführen beider dfs jetzt durch merge,\n",
    "# OHNE dass Indices passen:\n",
    "df.merge(geo_df, on=\"Location\")\n",
    "# how ist standardmäßig auf 'inner' gesetzt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T17:39:30.543600100Z",
     "start_time": "2024-01-27T17:39:30.515116300Z"
    }
   },
   "outputs": [],
   "source": [
    "# Achtung: andere defaults bei .merge() als bei .join()\n",
    "# bei .merge() ist inner join default (bei .join() ist es left)\n",
    "df.merge(geo_df, on=\"Location\", how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### merge() erlaubt uns auch das Verbinden von unterschiedlich bezeichneten Spalten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T17:39:37.657666800Z",
     "start_time": "2024-01-27T17:39:37.651840800Z"
    }
   },
   "outputs": [],
   "source": [
    "# Umbennenen der Spalte Location von geo_df in Stadt\n",
    "geo_df.rename(columns={\"Location\": \"Stadt\"}, inplace=True)\n",
    "geo_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verwenden von right_on und left_on, um unterschiedliche\n",
    "# Spaltennamen zu mergen\n",
    "df.merge(geo_df, left_on=\"Location\", right_on=\"Stadt\", how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Übungsaufgabe `merge`\n",
    "\n",
    "Nachfolgender Dictionaries enthalten Daten zu Kunden und Produktkäufen.\n",
    "Deine Aufgabe ist es, daraus zwei DataFrames zu erstellen und danach die beiden DataFrames so mitttels merge zu verbinden, dass zu allen Produktdaten die entsprechenden Kundendaten erscheinen, soweit verfügbar (ansonsten NaN-Werte)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_data = {\n",
    "    'CustomerID': [101, 102, 103, 104, 105, 106, 107],\n",
    "    'CustomerName': ['Alice', 'Bob', 'Charlie', 'David', 'Eva', 'Frank', 'Grace'],\n",
    "    'Email': ['alice@mail.com', 'bob@mail.com', 'charlie@mail.com', 'david@mail.com', 'eva@mail.com', 'frank@mail.com', 'grace@mail.com'],\n",
    "    'JoinDate': ['2022-05-01', '2021-06-15', '2020-08-20', '2022-11-25', '2023-01-05', '2021-09-10', '2020-12-31']\n",
    "}\n",
    "\n",
    "purchase_data = {\n",
    "    'ClientID': [101, 102, 103, 108, 105, 106, 107, 102],\n",
    "    'ProductID': [201, 202, 203, 204, 205, 206, 207, 205],\n",
    "    'PurchaseDate': ['2023-01-10', '2023-02-15', '2023-01-20', '2023-03-10', '2023-01-30', '2023-03-05', '2023-01-25', '2023-04-01'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
